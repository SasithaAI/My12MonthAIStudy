{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an exercise in **what not to do!**\n",
    "\n",
    "# The shocking case of junk food and acne\n",
    "\n",
    "You have been asked to investigate a link between jukn food and acne. \n",
    "\n",
    "You have been given a dataset, `junkfood.csv`, which contains several columns. First, a numeric column representing a self-reported value from 0 to 10 of \"How badly do you present with acne?\", with 0 being not at all and 10 being ever-present and severe. Then there is a column which describes their most significant contribution to junk food (ie do they most often eat chocolate, drink softdrink, or something else), and the third column details an estimate for how many times a month they partake in junk food."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acne</th>\n",
       "      <th>Food</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Burgers</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Chocolate</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Ice cream</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ice cream</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Cake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Acne       Food  Frequency\n",
       "0     5    Burgers         21\n",
       "1     6  Chocolate         26\n",
       "2     5  Ice cream         17\n",
       "3     1  Ice cream          1\n",
       "4     0       Cake          2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"junkfood.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for a global link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Burgers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:11056\u001b[39m, in \u001b[36mDataFrame.corr\u001b[39m\u001b[34m(self, method, min_periods, numeric_only)\u001b[39m\n\u001b[32m  11054\u001b[39m cols = data.columns\n\u001b[32m  11055\u001b[39m idx = cols.copy()\n\u001b[32m> \u001b[39m\u001b[32m11056\u001b[39m mat = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m  11058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mpearson\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m  11059\u001b[39m     correl = libalgos.nancorr(mat, minp=min_periods)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:1998\u001b[39m, in \u001b[36mDataFrame.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1996\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1997\u001b[39m     dtype = np.dtype(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1999\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[32m   2000\u001b[39m     result = np.asarray(result, dtype=dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:1694\u001b[39m, in \u001b[36mBlockManager.as_array\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1692\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1693\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m     arr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[32m   1696\u001b[39m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/managers.py:1753\u001b[39m, in \u001b[36mBlockManager._interleave\u001b[39m\u001b[34m(self, dtype, na_value)\u001b[39m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1752\u001b[39m         arr = blk.get_values(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m1753\u001b[39m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m = arr\n\u001b[32m   1754\u001b[39m     itemmask[rl.indexer] = \u001b[32m1\u001b[39m\n\u001b[32m   1756\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask.all():\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Burgers'"
     ]
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a small positive correlation between frequency of eating junk food and having bad acne. Let's look at a subset to compare extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.5357833655706\n",
      "14.878205128205128\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df[\"Acne\"] < 3, \"Frequency\"].mean())\n",
    "print(df.loc[df[\"Acne\"] > 7, \"Frequency\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only looks like a small relationship.\n",
    "\n",
    "Let's state the null hypothesis a bit better. \n",
    "\n",
    "Null hypothesis: *The frequency of junk food does not cause (correlate) with acne.*\n",
    "\n",
    "To test this we can use Pearson's correlation test in scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation is 0.018, with p-value of 0.5662\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "correlation, pvalue = pearsonr(df[\"Acne\"], df[\"Frequency\"])\n",
    "print(f\"Correlation is {correlation:.3f}, with p-value of {pvalue:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a significant p-value, so we cannot reject the null hypothesis.\n",
    "\n",
    "But wait, what if we ask if any one food is correlated. Let's check each food item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant correlation for Burgers\n",
      "No significant correlation for Chocolate\n",
      "No significant correlation for Ice cream\n",
      "Significant correlation (pvalue 0.0326) between Cake: 0.229!!\n",
      "No significant correlation for Donuts\n",
      "No significant correlation for Lollies\n",
      "No significant correlation for Pure Sugar\n",
      "No significant correlation for Cheese Pizza\n",
      "No significant correlation for Brownies\n",
      "No significant correlation for Milkshakes\n",
      "No significant correlation for Soft Drink\n"
     ]
    }
   ],
   "source": [
    "foods = df[\"Food\"].unique()\n",
    "alpha = 0.05\n",
    "for f in foods:\n",
    "    df2 = df.loc[df[\"Food\"] == f]\n",
    "    correlation, pvalue = pearsonr(df2[\"Acne\"], df2[\"Frequency\"])\n",
    "    if pvalue < alpha:\n",
    "        print(f\"Significant correlation (pvalue {pvalue:0.4f}) between {f}: {correlation:.3f}!!\")\n",
    "    else:\n",
    "        print(f\"No significant correlation for {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DAMMIT CAKE!**\n",
    "\n",
    "This is just unimaginable. How will the world take this devastating news?\n",
    "\n",
    "****\n",
    "\n",
    "Right, so this is an example of significance hunting. By drilling down into our data when we initially don't find results and comparing a large number of hypotheses we are bound to eventually call something statistically significant. In this case, the data was generated without any correlation at all, this is just a statistical fluctuation. But in an effort to find results we could publish an article claiming a statistically significant correlation between cake and acne, and then the media would run with it, and its all junk science.\n",
    "\n",
    "*The moral of the story here is that you should pick you value of $\\alpha$ (in our case, 0.05) based on the number of tests to try and minimise false positives.*\n",
    "\n",
    "*Also*, keep in mind for when you next see media about correlation between two things, chocolate and heart disease, wine and longevity, etc, that just because you have the strength in your data to determine correlation with significance doesn't mean that *amount* of correlation is significance. \n",
    "\n",
    "With a large enough data sample, you can detect a correlation of 0.0001 with statistical significance.\n",
    "\n",
    "And to end on a fun note [here is a relevant xkcd which inspired the acne link in this example](https://xkcd.com/882/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
